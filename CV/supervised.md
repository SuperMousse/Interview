1. k nearest neighbours

2. principal component analysis: 无监督学习, 放这为了和线性判别分析做对比
   用处: 高维数据可视化(投影到二维或者三维);  
        作为数据预处理方法用在图像检索等问题中;  
        人脸识别特征脸(人脸数据集分解为不同的特征向量, 排列后就是特征脸, 每幅图可以看成特征脸的线性组合)

   输入：n维样本集X={x_1, x_2, ..., x_n}，要降维到的维数$n^{'}$.  
   输出：降维后的样本集Y  
   
    a.对所有的样本进行中心化 x_i = x_i - 1/m \sum{x_j}  
    b.计算样本的协方差矩阵C = 1/n XX^T  
    c.求出协方差矩阵的特征值及对应的特征向量  
    d.将特征向量按对应特征值大小从上到下按行排列成矩阵，取前k行组成矩阵P  
    e.Y=PX即为降维到k维后的数据  

3. linear discriminant analysis: 不同于PCA, 是监督学习方法, 又叫Fisher线性判别    
   核心: 将所有的数据投影到一个高维直线上, 使得投影后类内方差最小，类间方差最大    
